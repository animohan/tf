{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-fe8bbe7e1aea>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/mnist/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/mnist/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting data/mnist/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: __init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('data/mnist', one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import examples.utils as utils\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.9.0'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/mnist/train-images-idx3-ubyte.gz already exists\n",
      "data/mnist/train-labels-idx1-ubyte.gz already exists\n",
      "data/mnist/t10k-images-idx3-ubyte.gz already exists\n",
      "data/mnist/t10k-labels-idx1-ubyte.gz already exists\n"
     ]
    }
   ],
   "source": [
    "mnist_path = 'data/mnist'\n",
    "utils.download_mnist(mnist_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "batch_size = 128\n",
    "epochs = 30\n",
    "n_train = 60000\n",
    "n_test = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,val,test = utils.read_mnist(mnist_path, flatten = True)\n",
    "tf.reset_default_graph() #Useful to reset graph, because else tf throws\n",
    "                         # errors with named entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "- Use tf to create the dataset\n",
    "- Need to one set for training and test.\n",
    "- Setting shuffle, shuffles the data\n",
    "'''\n",
    "\n",
    "train_data = tf.data.Dataset.from_tensor_slices(train)\n",
    "train_data = train_data.shuffle(10000)\n",
    "test_data = tf.data.Dataset.from_tensor_slices(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initilize the data with specific batch size\n",
    "train_data = train_data.batch(batch_size)\n",
    "test_data = test_data.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Iterator represents thse state of iterating through a dataset\n",
    "Iterator.from_structure :- creates a new uninitialzed iterator with a \n",
    " given structure\n",
    " \n",
    " This iterator constructing method can be used to create an iterator that\n",
    " is reusable with many different datasets\n",
    " \n",
    " To initialize it with particular dataset:- Iterator.make_initializer(dataset)\n",
    "'''\n",
    "iterator = tf.data.Iterator.from_structure(train_data.output_types, train_data.output_shapes)\n",
    "img,label = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the itertor with two different datasets\n",
    "train_init = iterator.make_initializer(train_data)\n",
    "test_init = iterator.make_initializer(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note the shapes are different from Andrew's class\n",
    "# X = img = (n x d) = (n0 x n1) = 55000 x 784\n",
    "# w = (n1 x n2)\n",
    "# b = (1 x n2)\n",
    "w = tf.get_variable(shape = (784,10), name = \"weights\", initializer = tf.random_normal_initializer(0,0.01))\n",
    "b = tf.get_variable(shape = (1,10), name = \"bias\", initializer = tf.zeros_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = tf.matmul(img,w) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-58-ad8c916cb769>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#loss\n",
    "entropy = tf.nn.softmax_cross_entropy_with_logits(labels = label, logits = logits, name = \"entropy\")\n",
    "loss = tf.reduce_mean(entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test set accuracty\n",
    "preds = tf.nn.softmax(logits)\n",
    "correct_preds = tf.equal(tf.argmax(preds,1),tf.argmax(label,1))\n",
    "'''\n",
    "tf.argmax(input, axis)\n",
    "axis 1 -> index of max element in each row.\n",
    "tf.argmax(preds,1):- index of max (highest logit)\n",
    "tf.argmax(label,1):- one hot encoded hence, only 1 entry will have label 1\n",
    "'''\n",
    "\n",
    "accuracy = tf.reduce_sum(tf.cast(correct_preds, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss for epoch 0 is 0.3652790895728178\n",
      "Average loss for epoch 1 is 0.29372095779277557\n",
      "Average loss for epoch 2 is 0.2826418680853622\n",
      "Average loss for epoch 3 is 0.27794407198941984\n",
      "Average loss for epoch 4 is 0.2728675678025844\n",
      "Average loss for epoch 5 is 0.2703637342813403\n",
      "Average loss for epoch 6 is 0.2694084622832232\n",
      "Average loss for epoch 7 is 0.26536988818714785\n",
      "Average loss for epoch 8 is 0.26582398643327315\n",
      "Average loss for epoch 9 is 0.2632793801468472\n",
      "Average loss for epoch 10 is 0.2618862616461377\n",
      "Average loss for epoch 11 is 0.26017864862846773\n",
      "Average loss for epoch 12 is 0.25852942934562995\n",
      "Average loss for epoch 13 is 0.26248136240729064\n",
      "Average loss for epoch 14 is 0.2565573022895774\n",
      "Average loss for epoch 15 is 0.26014907152153727\n",
      "Average loss for epoch 16 is 0.2580857612105996\n",
      "Average loss for epoch 17 is 0.2550546283118947\n",
      "Average loss for epoch 18 is 0.25486639568278957\n",
      "Average loss for epoch 19 is 0.25429718615703806\n",
      "Average loss for epoch 20 is 0.2529427922742311\n",
      "Average loss for epoch 21 is 0.25485169081840403\n",
      "Average loss for epoch 22 is 0.2512409203620844\n",
      "Average loss for epoch 23 is 0.2515459250572116\n",
      "Average loss for epoch 24 is 0.2538154857623023\n",
      "Average loss for epoch 25 is 0.25366497661831766\n",
      "Average loss for epoch 26 is 0.2501785036263078\n",
      "Average loss for epoch 27 is 0.2530286833643913\n",
      "Average loss for epoch 28 is 0.24768494819832404\n",
      "Average loss for epoch 29 is 0.25269765578383624\n",
      "Total time: 22.050212144851685\n",
      "Accuracty:0.9176\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    start_time = time.time()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        sess.run(train_init) #get samples from the data\n",
    "        total_loss = 0\n",
    "        n_batches = 0\n",
    "        \n",
    "        try:\n",
    "            while True:\n",
    "                _,l = sess.run([optimizer,loss])\n",
    "                total_loss += l\n",
    "                n_batches += 1\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass\n",
    "        \n",
    "        print(\"Average loss for epoch {0} is {1}\".format(i, total_loss/n_batches))\n",
    "    print(\"Total time: {0}\".format(time.time()-start_time))\n",
    "    \n",
    "    sess.run(test_init)\n",
    "    total_correct_preds = 0\n",
    "    try:\n",
    "        while True:\n",
    "            accuracy_batch = sess.run(accuracy)\n",
    "            total_correct_preds += accuracy_batch\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        pass\n",
    "    \n",
    "    print(\"Accuracty:{0}\".format(total_correct_preds/n_test))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
