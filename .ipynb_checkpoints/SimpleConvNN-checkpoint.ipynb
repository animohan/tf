{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filter_size1 = 5\n",
    "num_filters1 = 16\n",
    "\n",
    "filter_size2 = 5\n",
    "num_filters2 = 36\n",
    "\n",
    "fc_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "data = input_data.read_data_sets('data/MNIST/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of:\n",
      "- Training-set:\t\t55000\n",
      "- Test-set:\t\t10000\n",
      "- Validation-set:\t5000\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of:\")\n",
    "print(\"- Training-set:\\t\\t{}\".format(len(data.train.labels)))\n",
    "print(\"- Test-set:\\t\\t{}\".format(len(data.test.labels)))\n",
    "print(\"- Validation-set:\\t{}\".format(len(data.validation.labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.test.cls = np.argmax(data.test.labels, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_size = 28\n",
    "img_size_flat = img_size * img_size\n",
    "img_shape = (img_size, img_size)\n",
    "num_channels = 1\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_images(images, cls_true, cls_pred = None):\n",
    "    assert len(images) == len(cls_true) == 9\n",
    "    \n",
    "    fig,axes = plt.subplots(3,3)\n",
    "    fig.subplots_adjust(hspace = 0.3, wspace = 0.3)\n",
    "    \n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(images[i].reshape(img_shape), cmap = 'binary')\n",
    "        \n",
    "        if cls_pred is None:\n",
    "            xlabel = \"True : {0}\".format(cls_true[i])\n",
    "        else:\n",
    "            xlabel = \"True: {0}, Pred: {1}\".format(cls_true[i],cls_pred[i])\n",
    "        \n",
    "        ax.set_xlabel(xlabel)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUMAAAD5CAYAAAC9FVegAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niogA8P/o82uc545QuQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f62d7ce40b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images = data.test.images[0:9]\n",
    "cls_true = data.test.cls[0:9]\n",
    "plot_images(images = images, cls_true = cls_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_weights(shape):\n",
    "    return(tf.Variable(tf.truncated_normal(shape, stddev = 0.05)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_biases(length):\n",
    "    return(tf.Variable(tf.constant(0.05, shape = [length])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_conv_layer(input, num_input_channels, filter_size, num_filters, use_pooling = True):\n",
    "    shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "    weights = new_weights(shape = shape)\n",
    "    biases = new_biases(length = num_filters)\n",
    "    \n",
    "    layer = tf.nn.conv2d(input = input, filter = weights, strides = [1,1,1,1], padding = 'SAME')\n",
    "    layer = layer + biases\n",
    "    \n",
    "    layer = tf.nn.max_pool(value = layer, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'SAME')\n",
    "    \n",
    "    layer = tf.nn.relu(layer)\n",
    "    \n",
    "    return(layer, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten_layer(layer):\n",
    "    layer_shape = layer.get_shape()\n",
    "    num_features = layer_shape[1:4].num_elements()\n",
    "    layer_flat = tf.reshape(layer, [-1, num_features])\n",
    "    return(layer_flat, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_fc_layer(input, num_inputs, num_outputs, use_relu = True):\n",
    "    weights = new_weights(shape = [num_inputs, num_outputs])\n",
    "    biases = new_biases(length = num_outputs)\n",
    "    layer = tf.matmul(input, weights) + biases\n",
    "    layer = tf.nn.relu(layer)\n",
    "    return(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape = [None, img_size_flat], name = 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_image = tf.reshape(x, [-1, img_size, img_size, num_channels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true = tf.placeholder(tf.float32, shape = [None, num_classes],name = 'y_true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true_cls = tf.argmax(y_true, dimension = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layer_conv1, weights_conv1 = new_conv_layer(input = x_image,\n",
    "                                           num_input_channels = num_channels,\n",
    "                                           filter_size = filter_size1,\n",
    "                                           num_filters = num_filters1,\n",
    "                                           use_pooling = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_1:0' shape=(?, 14, 14, 16) dtype=float32>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_conv2, weights_conv2 = new_conv_layer(input = layer_conv1, num_input_channels = num_filters1,\n",
    "                                           filter_size = filter_size2,\n",
    "                                           num_filters = num_filters2,\n",
    "                                           use_pooling = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_3:0' shape=(?, 7, 7, 36) dtype=float32>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_conv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layer_flat, num_features = flatten_layer(layer_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape_1:0' shape=(?, 1764) dtype=float32>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1764"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layer_fc1 = new_fc_layer(input = layer_flat, num_inputs = num_features, num_outputs = fc_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_5:0' shape=(?, 128) dtype=float32>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_fc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_fc2 = new_fc_layer(input = layer_fc1, num_inputs = fc_size, num_outputs = num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_6:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = tf.nn.softmax(layer_fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_cls = tf.argmax(y_pred, dimension = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits = layer_fc2, labels = y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate = 1e-4).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(y_pred_cls ,  y_true_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_iterations = 0\n",
    "\n",
    "def optimize(num_iterations):\n",
    "    global total_iterations\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for i in range(total_iterations, total_iterations + num_iterations):\n",
    "        x_batch, y_true_batch = data.train.next_batch(train_batch_size)\n",
    "        feed_dict_train = {x: x_batch, y_true: y_true_batch}\n",
    "        session.run(optimizer, feed_dict = feed_dict_train)\n",
    "        if i % 100 == 0:\n",
    "            acc = session.run(accuracy, feed_dict= feed_dict_train)\n",
    "            msg = \"Optimization Iteration : {0:>6}, Training Accuracy : {1:>6.1%}\"\n",
    "            print(msg.format(i+1, acc))\n",
    "    \n",
    "    total_iterations = total_iterations + num_iterations\n",
    "    end_time = time.time()\n",
    "    time_diff = end_time = start_time\n",
    "    #print(\"Time: \" + str(timedelta(seconds = int(round(time_diff)))))\n",
    "    print(\"Time: \", time_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_batch_size = 256\n",
    "\n",
    "def print_test_accuracy():\n",
    "    num_test = len(data.test.images)\n",
    "    cls_pred = np.zeros(shape = num_test, dtype = np.int)\n",
    "    i = 0\n",
    "    while i < num_test:\n",
    "        j = min(i + test_batch_size, num_test)\n",
    "        images = data.test.images[i:j, :]\n",
    "        labels = data.test.labels[i:j, :]\n",
    "        feed_dict = {x: images,\n",
    "                    y_true: labels}\n",
    "        cls_pred[i:j] = session.run(y_pred_cls, feed_dict = feed_dict)\n",
    "        i = j\n",
    "    \n",
    "    cls_true = data.test.cls\n",
    "    correct = (cls_true == cls_pred)\n",
    "    correct_sum = correct.sum()\n",
    "    \n",
    "    acc = float(correct_sum) / num_test\n",
    "    msg = \"Accuracy on Test Set : {0:.1%} ({1} / {2})\"\n",
    "    print(msg.format(acc, correct_sum, num_test))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Set : 9.7% (969 / 10000)\n"
     ]
    }
   ],
   "source": [
    "print_test_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration :      1, Training Accuracy :  18.8%\n",
      "Time:  1496633956.4518738\n"
     ]
    }
   ],
   "source": [
    "optimize(num_iterations = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Set : 14.6% (1463 / 10000)\n"
     ]
    }
   ],
   "source": [
    "print_test_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration :    701, Training Accuracy :  73.4%\n",
      "Optimization Iteration :    801, Training Accuracy :  73.4%\n",
      "Optimization Iteration :    901, Training Accuracy :  70.3%\n",
      "Optimization Iteration :   1001, Training Accuracy :  70.3%\n",
      "Optimization Iteration :   1101, Training Accuracy :  76.6%\n",
      "Optimization Iteration :   1201, Training Accuracy :  84.4%\n",
      "Optimization Iteration :   1301, Training Accuracy :  85.9%\n",
      "Optimization Iteration :   1401, Training Accuracy :  68.8%\n",
      "Optimization Iteration :   1501, Training Accuracy :  67.2%\n",
      "Optimization Iteration :   1601, Training Accuracy :  73.4%\n",
      "Time:  1496634028.379516\n"
     ]
    }
   ],
   "source": [
    "optimize(num_iterations = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Set : 77.0% (7703 / 10000)\n"
     ]
    }
   ],
   "source": [
    "print_test_accuracy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
